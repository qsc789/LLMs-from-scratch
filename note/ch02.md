# Tokenizing text 文本分词
+ tokenize text, which means breaking text into smaller units, such as individual words and punctuation characters
*对文本进行标记，这意味着将文本分成更小的单元，例如单个单词和标点符号*
```go
import os# 文件系统操作库
import urllib.request# URL处理库

if not os.path.exists("the-verdict.txt"):# 判断文件是否存在
    url = ("https://raw.githubusercontent.com/rasbt/"
           "LLMs-from-scratch/main/ch02/01_main-chapter-code/"
           "the-verdict.txt")
    file_path = "the-verdict.txt"
    urllib.request.urlretrieve(url, file_path)# 下载文件，并保存到指定路径
```
*注意要保证URL都可以访问到（挂梯子）*
### 使用正则表达式分割文本
```go
import re # 正则表达式库
text = "Hello, world. This, is a test."
result = re.split(r'(\s)', text)# 使用正则表达式分割文本
print(result)
```
对逗号和句点也进行拆分
```go
result = re.split(r'([,.]|\s)', text)# 但会产生空白字符串，需要过滤掉
print(result)
result = [item for item in result if item.strip()]# 过滤空白字符串
print(result)
```
处理带复杂标点符号的文本
```go
text = "Hello, world. Is this-- a test?"
result = re.split(r'([,.:;?_!"()\']|--|\s)', text)
result = [item.strip() for item in result if item.strip()]
print(result)
```
```go
preprocessed = re.split(r'([,.:;?_!"()\']|--|\s)', raw_text)
preprocessed = [item.strip() for item in preprocessed if item.strip()]
print(preprocessed[:30])# 前30个token
print(len(preprocessed))# token数
```
### Token转化为Token ID
接下来，我们将文本令牌转换为令牌 ID，以便稍后通过嵌入层进行处理
![](/note/assets/img//ch02/ch02_01.png)
从这些 Token 中，我们现在可以构建一个包含所有唯一 Token 的词汇表
下面，我们使用一个小词汇表来说明一个简短的示例文本的分词
![](/note/assets/img//ch02/ch02_02.png)
encode 函数将文本转换为令牌 ID
decode 函数将令牌 ID 转换回文本
![](/note/assets/img//ch02/ch02_03.png)
### 添加特殊的上下文tokens
为未知单词添加一些 “特殊” 标记并表示文本的结尾很有用
![](/note/assets/img//ch02/ch02_04.png)
其中一些特殊令牌是
+ [BOS]（序列开始）标记文本的开始
+ [EOS]（序列结束）标记文本结束的位置（通常用于连接多个不相关的文本，例如，两篇不同的维基百科文章或两本不同的书籍，等等）
+ [PAD]（填充）如果我们训练批量大小大于 1 的 LLMs（我们可能包含多个不同长度的文本;使用填充标记，我们将较短的文本填充到最长的长度，以便所有文本的长度相等）
+ [UNK] 表示词汇表中未包含的单词
+ ![](/note/assets/img//ch02/ch02_05.png)
### BytePair 编码
![](/note/assets/img//ch02/ch02_06.png)
![](/note/assets/img//ch02/ch02_07.png)
### 使用滑动窗口进行数据采样
![](/note/assets/img//ch02/ch02_08.png)
在介绍了注意力机制之后，我们将在后面的章节中处理下一个单词的预测，现在，我们实现了一个简单的数据加载器，它迭代输入数据集并返回移动 1 的输入和目标，我们使用滑动窗口方法，将位置改变 +1：
![](/note/assets/img//ch02/ch02_09.png)
使用 stride 等于上下文长度的示例（此处为 4），如下所示
![](/note/assets/img//ch02/ch02_10.png)
### 创建token embeddings
让我们使用嵌入层将标记嵌入到连续向量表示中
![](/note/assets/img//ch02/ch02_11.png)
![](/note/assets/img//ch02/ch02_12.png)
### 编码字位置
![](/note/assets/img//ch02/ch02_13.png)
![](/note/assets/img//ch02/ch02_14.png)
要创建LLM，我们只需添加标记和位置嵌入：
在输入处理工作流的初始阶段，输入文本被分割为单独的标记
在此分段之后，这些令牌将根据预定义的词汇表转换为令牌 ID：
![](/note/assets/img//ch02/ch02_15.png)