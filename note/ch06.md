# 第 6 章：文本分类的微调
## 6.1 不同类别的微调
微调语言模型的最常见方法是指令微调和分类微调,指令微调，如下所示，是下一章的主题
![](/note/assets/img/ch06/ch06_01.png)
+ 如果您具有机器学习背景，则分类微调是您可能已经熟悉的过程，例如，它类似于训练卷积网络来对手写数字进行分类
+ 在分类微调中，我们有特定数量的类标签（例如，“spam”和“not spam”），模型可以输出
+ 分类微调模型只能预测它在训练期间看到的类（例如，“垃圾邮件”或“非垃圾邮件”），而指令微调模型通常可以执行许多任务
+ 我们可以将分类微调模型视为非常专业的模型;在实践中，创建专业化模型比创建在许多不同任务上表现良好的通用模型要容易得多
![](/note/assets/img/ch06/ch06_02.png)
## 6.2 准备数据集
![](/note/assets/img/ch06/ch06_03.png)
本节准备我们用于分类微调的数据集,我们使用由垃圾邮件和非垃圾邮件组成的数据集来微调 LLM 对其进行分类
## 6.3 创建数据加载器
+ 请注意，短信的长度不同;如果我们想将多个训练样本批量组合在一起，我们必须
  1.截断所有消息为数据集或批次中最短消息的长度
  2.将所有消息填充到数据集或批次中最长消息的长度
+ 我们选择选项 2 并将所有消息填充到数据集中最长的消息
+ 为此，我们使用 <|endoftext|> 作为填充标记，如第 2 章所述
  ![](/note/assets/img/ch06/ch06_04.png)
  接下来，我们使用数据集来实例化数据加载器，这与前几章中创建数据加载器类似
  ![](/note/assets/img/ch06/ch06_05.png)
## 6.4 使用预训练权重初始化模型
  ![](/note/assets/img/ch06/ch06_06.png)
## 6.5 添加分类头
  ![](/note/assets/img/ch06/ch06_07.png)
  在本节中，我们将修改预训练的 LLM，使其为分类微调做好准备
  + 我们可以看到我们在第 4 章中实现的架构整齐地布局,目标是替换和微调输出层
+ 为了实现这一点，我们首先冻结模型，这意味着我们使所有层都是不可训练的,然后，我们替换输出层 （model.out_head）
+ 它最初将层输入映射到 50,257 个维度（词汇表的大小）,由于我们对二元分类模型进行了微调（预测 2 个类别，“spam”和“not spam”）
+ 因此我们可以替换如下所示的输出层，默认情况下它是可训练的
+ 请注意，我们使用 BASE_CONFIG[“emb_dim”]（等于 “gpt2-small （124M）” 模型中的 768）来保持下面的代码更通用
+ 从技术上讲，只需训练输出层就足够了
+ 但是，正如我在 Finetuning Large Language Models 中发现的那样，实验表明，微调其他层可以显著提高性能
+ 因此，我们还使最后一个 transformer 模块和最后一个 LayerNorm 模块连接起来，将最后一个 transformer 模块连接到输出层，使其可训练
    ![](/note/assets/img/ch06/ch06_08.png)
+ 如前几章所述，对于每个 input token，都有一个 output vector
+ 由于我们向模型提供了具有 4 个输入标记的文本样本，因此输出由上面的 4 个 2 维输出向量组成
  ![](/note/assets/img/ch06/ch06_09.png)
+ 在第 3 章中，我们讨论了注意力机制，它将每个输入标记连接到另一个输入标记
+ 在第 3 章中，我们还介绍了类 GPT 模型中使用的因果注意力掩码;此因果掩码允许当前 Token 仅关注当前和之前的 Token 位置
+ 基于这种因果注意力机制，第 4 个（最后一个）标记在所有标记中包含最多的信息，因为它是唯一包含所有其他标记信息的标记
+ 因此，我们对最后一个令牌特别感兴趣，我们将针对垃圾邮件分类任务对其进行微调
  ![](/note/assets/img/ch06/ch06_10.png)
## 6.6 计算分类损失和准确率
 ![](/note/assets/img/ch06/ch06_11.png)
 在解释损失计算之前，让我们简单了解一下模型输出是如何转换为类标签的
  ![](/note/assets/img/ch06/ch06_12.png)
+  与第 5 章类似，我们通过 softmax 函数将输出 （logits） 转换为概率分数，然后通过 argmax 函数获得最大概率值的索引位置
+  请注意，如第 5 章所述，softmax 函数在这里是可选的，因为最大的输出对应于最大的概率分数
+  我们可以应用这个概念来计算所谓的分类准确性，它计算给定数据集中正确预测的百分比
+  为了计算分类准确率，我们可以将前面基于 argmax 的预测代码应用于数据集中的所有示例，并按如下方式计算正确预测的分数：
## 6.7 在监督数据上微调模型
+ 在本节中，我们将定义并使用训练函数来提高模型的分类准确率
+ 唯一的两个区别是我们现在
  1.跟踪看到的训练样本数 （examples_seen），而不是看到的标记数
  2.计算每个 epoch 后的准确性，而不是在每个 epoch 后打印示例文本
   ![](/note/assets/img/ch06/ch06_13.png)
   训练集和验证集的损失函数
  ![](/note/assets/img/ch06/ch06_14.png)
  精度图表
  ![](/note/assets/img/ch06/ch06_15.png)
## 6.8 使用 LLM 作为垃圾邮件分类器
  ![](/note/assets/img/ch06/ch06_16.png)
  + 最后，让我们在实际使用微调后的 GPT 模型
  + 下面的 classify_review 函数实现了类似于我们之前实现的 SpamDataset 的数据预处理步骤
  + 然后，该函数从模型中返回预测的整数类标签，并返回相应的类名